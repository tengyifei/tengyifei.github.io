<!doctype html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Eliminating JNI overhead: tricks and trade-offs | Thinking and Computing</title>
        <!-- Material Library -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/material-design-lite/1.1.3/material.min.css" integrity="sha256-8/FvSMufaMDFDGPISKeLSup0kzLXG2IjRnmpPtcyxjY=" crossorigin="anonymous">
        <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">

        <link rel="stylesheet" type="text/css" href="../css/default.css" />
    </head>
    <body>
        <div id="tnc-background"></div>
        <script>
(function() {
    var imageNames = [
        
        'images/cover/bridge.jpg',
        
        'images/cover/newyork.jpg',
        
    ];
    var img = imageNames[Math.floor(Math.random() * imageNames.length)];
    document.getElementById('tnc-background').style = 'background-image: url(\'/' + img + '\');';
})();
</script>

        <div class="tnc-main tnc-layout mdl-layout mdl-js-layout">
          <header class="mdl-layout__header mdl-layout__header--transparent mdl-layout__header--scroll">
            <!-- Top row, always visible -->
            <div class="mdl-layout__header-row">
              <!-- Title -->
              <span class="mdl-layout-title"><a href="../">Thinking and Computing</a></span>
              <div class="mdl-layout-spacer"></div>
              <!-- Navigation -->
              <nav class="mdl-navigation">
                  <a class="mdl-navigation__link" href="../">Home</a>
                  <a class="mdl-navigation__link" href="../about.html">About</a>
                  <a class="mdl-navigation__link" href="../contact.html">Contact</a>
                  <a class="mdl-navigation__link" href="../archive.html">Archive</a>
              </nav>
            </div>
          </header>
          <div class="mdl-layout__drawer">
            <span class="mdl-layout-title">Browse T&amp;C</span>
            <nav class="mdl-navigation">
              <a class="mdl-navigation__link" href="../">Home</a>
              <a class="mdl-navigation__link" href="../about.html">About</a>
              <a class="mdl-navigation__link" href="../contact.html">Contact</a>
              <a class="mdl-navigation__link" href="../archive.html">Archive</a>
            </nav>
          </div>
          <main class="tnc-main mdl-layout__content">
            <div class="tnc-container mdl-grid">
              <div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
              <div class="tnc-content mdl-color--white mdl-shadow--4dp content mdl-color-text--grey-800 mdl-cell mdl-cell--8-col">
                  <h1>Eliminating JNI overhead: tricks and trade-offs</h1>
<div class="info">
    Posted on March 30, 2014
    
</div>

<p>
Out of all Java codes convertible to C using the Java Native Interface, the following breed is the hardest to optimize: methods that are invoked very frequently and have low run time. More often than not the overhead entailed by JNI becomes significant enough that it offsets any gain in speed brought by native code, or worse, making the resulting program even slower. When optimizing a Java-based matrix multiplication program, I encountered a lot of such methods. Most of them are in the form of nested loops responsible of manipulating matrices on the order of 100 elements. Such trivial methods are generally not considered during optimization, but this time the sheer number of invocations have placed them at the top of the hot spot list. 
</p>
[caption id=“” align=“aligncenter” width=“507”]<img class=" " src="https://static.thinkingandcomputing.com/2014/03/hotspot.png" alt="Lots of invocations amplifies the JNI overhead" width="507" height="105" /> Death by the numbers[/caption]
<p>
Without proper optimization, the JNI-ed version actually takes more time than the Java implementation, due to various overhead. 
</p>
<h2>
Doing away with JNI altogether?
</h2>
<p>
There exists a <em>de-jure</em> solution: implement custom Java intrinsic functions. Many Java functions, mainly Math.* and Unsafe.*, already have their intrinsic counterparts built-in. When a piece of code calls one of such methods frequent enough, the JVM will directly inline the assembly from the intrinsic into the function call, effectively removing all call overhead while providing a fast implementation. While the built-in intrinsic functions are limited, it is possible to add your own intrinsics by modifying and recompiling the JVM. As stated in <a title="Intrinsic Methods in HotSpot VM" href="http://www.slideshare.net/RednaxelaFX/green-teajug-hotspotintrinsics02232013" target="_blank">this slide</a>, the Taobao JDK team implemented CRC32C intrinsics, which resulted in a more than 10x speed-up in CRC32 evaluation. 
</p>
<p>
<!--more-->
</p>
<p>
Though sounds attractive, it is very hard to do in reality. After battling hours with scarce documentation and convoluted dynamic code generation process, I finally gave up trying to convert those matrix multiplication functions into intrinsics, especially when it involves two-dimensional arrays. 
</p>
<p>
So it seems that JNI is still the most feasible way to integrate native code into Java programs. But at times the overhead is just too significant. Fortunately, there are a number of measures one can take to minimize it. After experimenting with them, I would like to discuss the effectiveness of each method along with their limitations: 
</p>
<h2>
<ol style="list-style-type: decimal">
<li>Use RegisterNatives
</h2>
<p>
The RegisterNatives function binds a C++ method to a Java method name. The JVM does that automatically if the C++ method is exported and a Java native method with the corresponding name can be found, but RegisterNatives exposes this process, allowing non-exported functions to be used. There has been discussions stating that registering JNI functions manually is faster as it frees JVM from enumerating all exported functions in a library and identifying any matches. I wrote some example code to test this claim: 
</p>
<pre lang="java" title="JNItest.java" class="crayon-selected">
package test;</li>
</ol>
<p>public class JNItest { static { System.loadLibrary(“jnitest”); } public static void main(String[] args) { long a = System.currentTimeMillis(); for (int i=0; i&lt;500000000; i++){ callJNIMethod1(); } long b = System.currentTimeMillis() - a; System.out.println(“Time taken per call (RegisterNatives):”+(b/500d)+“ns”);</p>
<pre><code>	a = System.currentTimeMillis();
	for (int i=0; i&amp;lt;500000000; i++){
		callJNIMethod2();
	}
	b = System.currentTimeMillis() - a;
	System.out.println(&quot;Time taken per call: &quot;+((double)b/500d)+&quot;ns&quot;);
}
private native static void callJNIMethod1();
private native static void callJNIMethod2();</code></pre>
}
</pre>
<p>
And the corresponding C++ file:
</p>
<pre lang="c++" title="jnitest.cpp">#include &lt;jni.h&gt;

//method definition
void callJNIMethod(JNIEnv* env, jobject);
extern "C" {
JNIEXPORT void JNICALL Java_test_JNItest_callJNIMethod2(JNIEnv *env, jobject obj);
}

static JNINativeMethod s_methods[] = {
   {"callJNIMethod1", "()V", (void*)callJNIMethod}
};

jint JNI_OnLoad(JavaVM* vm, void* reserved)
{
   JNIEnv *env = NULL;
   vm-&gt;GetEnv((void**)&amp;env, JNI_VERSION_1_6);

   //class name is "JNItest"
   jclass cls = env-&gt;FindClass("Ltest/JNItest;");
   int len = sizeof(s_methods) / sizeof(s_methods[0]);
   env-&gt;RegisterNatives(cls, s_methods, len);
   return JNI_VERSION_1_6;
}

void callJNIMethod(JNIEnv* env, jobject)
{
   //does nothing...
}

JNIEXPORT void JNICALL Java_test_JNItest_callJNIMethod2(JNIEnv *env, jobject obj){
   //to be auto-discovered by JVM
}
</pre>
<p>
After running the test program to compare the two, I discovered that using RegisterNatives actually cause JNI to be <em>slower</em>. But the difference is pretty much negligible. Therefore, RegisterNatives is not useful in reducing JNI overhead at all, contrary to some beliefs. The JNI call overhead is in fact quite small (less than 10ns on my environment), which means that a more insidious form of overhead lurks elsewhere, which brings us to:
</p>
<h2>
<ol start="2" style="list-style-type: decimal">
<li>Caching Java objects
</h2>
<p>
<!--raw-->
This measure is particularly helpful when a large number of arrays need to be passed to native code. Furthermore, JNI overhead actually increases linearly with the number of objects in an array passed to native code, even if the code is not using the array at all! To access an array from native code, JNI library functions Get&lt;Type&gt;ArrayElements need to be used.<!--/raw--> These functions typically copy the entire content of the array to a buffer location, and are undesirable. Functions such as GetPrimitiveArrayCritical, which instructs the JVM to make best effort to reveal the underlying pointer to the array, still add significant run time to the method, much larger than bare JNI call overhead alone. To mitigate this problem, it’s possible to call this function to obtain pointers to arrays at the start of program execution, cache the pointer in a global variable, and subsequent calls would not need to call the function again to access the array. Easy to implement, this strategy resolves most JNI overhead problems.
</p>
<p>
But speed is not everything. Performance gains aside, this method has some serious limitations. According to Sun documentation, the Get/ReleasePrimitiveArrayCritical methods are supposed to be used like a critical section, meaning that pointers obtained should be briefly released instead of being held over a long period of time. It also suggests that doing otherwise may cause the VM to pause garbage collection, unless it supports pinning. A quick search indicated that most modern JVMs do not support pinning due to it being detrimental to performance of concurrent mark-sweep GC. This is further validated by the fact that on my testing environment (jdk 1.8.0), GC was disabled once GetPrimitiveArrayCritical was called and never released, causing the VM to eventually throw OutOfMemoryError. Hence the pointer needs to be periodically released to let GC catch a breath.
</p>
<h2>
<ol start="3" style="list-style-type: decimal">
<li>Using ByteBuffer
</h2>
<p>
The thrid method is a compromise from the second one. Java ByteBuffers allocate memory regions exempt from GC, hence won’t be moved around or freed automatically. You can use ByteBuffer to create an area of the size equivalent to a float array, pass the pointer to the native code and perform operations on it. The ByteBuffer can be manipulated as an array of arbitrary primitive type by creating a view buffer. However, the downside is that existing code must be rewritten to use the view buffer to access the array.
</p></li>
</ol></li>
</ol>

              </div>
            </div>
          </main>
        </div>

        <script src="https://cdn.jsdelivr.net/material-design-lite/1.1.3/material.min.js" integrity="sha256-qeJNkhp5/Tnaa3Ovx49//j+Kn0Lx9ykNYJdLMxCwd1c=" crossorigin="anonymous" defer async></script>
    </body>
</html>
